# 维护指南

## 一、日常维护

### 1. 数据库维护

#### 备份数据库

**PostgreSQL 备份**:
```bash
# 完整备份
pg_dump -U postgres intent_system > backup_$(date +%Y%m%d).sql

# 压缩备份
pg_dump -U postgres intent_system | gzip > backup_$(date +%Y%m%d).sql.gz

# 仅备份数据（不含结构）
pg_dump -U postgres -a intent_system > data_backup.sql
```

**备份脚本** (建议添加到 cron):
```bash
#!/bin/bash
# backup_db.sh
BACKUP_DIR="/path/to/backups"
DATE=$(date +%Y%m%d_%H%M%S)
pg_dump -U postgres intent_system | gzip > "$BACKUP_DIR/backup_$DATE.sql.gz"
# 保留最近 7 天的备份
find "$BACKUP_DIR" -name "backup_*.sql.gz" -mtime +7 -delete
```

#### 恢复数据库

```bash
# 从备份恢复
psql -U postgres intent_system < backup_20260123.sql

# 从压缩备份恢复
gunzip < backup_20260123.sql.gz | psql -U postgres intent_system
```

#### 数据库清理

**清理过期结果**:
```sql
-- 删除过期的 RESULT 资源
DELETE FROM results 
WHERE fresh_until < NOW() - INTERVAL '7 days';

-- 删除过期的执行记录
DELETE FROM workflow_runs 
WHERE ended_at < NOW() - INTERVAL '30 days' 
AND status IN ('success', 'failed');
```

**清理旧日志**:
```sql
-- 根据业务需求清理旧数据
DELETE FROM workflow_runs 
WHERE created_at < NOW() - INTERVAL '90 days';
```

#### 数据库优化

**分析表统计信息**:
```sql
ANALYZE resources;
ANALYZE results;
ANALYZE workflow_runs;
```

**重建索引**:
```sql
REINDEX TABLE resources;
REINDEX TABLE results;
```

**查看表大小**:
```sql
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

### 2. 向量存储维护

#### ChromaDB 维护

**检查向量库大小**:
```bash
du -sh ./data/chroma
```

**清理向量库**:
```python
# 清理脚本
from services.retrieval.vector_store import VectorStore

vector_store = VectorStore()
# 删除特定资源
vector_store.delete_by_resource_id("res_doc_xxx")
```

**备份向量库**:
```bash
# 备份整个目录
tar -czf chroma_backup_$(date +%Y%m%d).tar.gz ./data/chroma
```

#### 重新索引

**单个资源重新索引**:
```bash
curl -X POST http://localhost:8000/v1/resources/res_doc_xxx/reindex
```

**批量重新索引**:
```python
# scripts/reindex_all.py
from services.resource_registry.service import ResourceService
from services.resource_registry.doc_processor import DocProcessor

processor = DocProcessor()
resources = ResourceService.list_resources(resource_type="DOC", status="active")

for resource in resources:
    print(f"重新索引: {resource.id}")
    processor.reindex_resource(resource.id)
```

### 3. 日志维护

#### 日志轮转

**使用 logrotate** (Linux):
```bash
# /etc/logrotate.d/intent-system
/path/to/logs/*.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
    create 0644 user group
}
```

**Python 日志轮转**:
```python
from logging.handlers import RotatingFileHandler

handler = RotatingFileHandler(
    'logs/app.log',
    maxBytes=10*1024*1024,  # 10MB
    backupCount=5
)
```

#### 日志分析

**查看错误日志**:
```bash
grep ERROR logs/app.log | tail -100
```

**统计错误类型**:
```bash
grep ERROR logs/app.log | awk '{print $5}' | sort | uniq -c | sort -rn
```

### 4. 性能监控

#### 监控指标

**关键指标**:
- API 响应时间
- 数据库查询时间
- LLM 调用时间（当前支持 OpenAI / DeepSeek / Claude / Qianwen，优先 .env 配置）
- 向量检索时间
- 错误率
- 请求量

**监控脚本示例**:
```python
# scripts/monitor.py
import requests
import time

def check_health():
    try:
        start = time.time()
        response = requests.get('http://localhost:8000/v1/health', timeout=5)
        duration = time.time() - start
        return {
            'status': response.status_code == 200,
            'duration_ms': duration * 1000
        }
    except Exception as e:
        return {'status': False, 'error': str(e)}

if __name__ == '__main__':
    result = check_health()
    print(f"健康检查: {result}")
```

#### 性能分析

**使用 cProfile**:
```bash
python -m cProfile -o profile.stats run.py
python -m pstats profile.stats
```

**使用 py-spy**:
```bash
pip install py-spy
py-spy record -o profile.svg -- python run.py
```

## 二、定期维护任务

### 1. 每日任务

- [ ] 检查服务健康状态
- [ ] 查看错误日志
- [ ] 检查数据库连接
- [ ] 监控 API 响应时间

### 2. 每周任务

- [ ] 数据库备份
- [ ] 清理过期数据
- [ ] 检查磁盘空间
- [ ] 审查错误日志

### 3. 每月任务

- [ ] 数据库优化（ANALYZE, REINDEX）
- [ ] 更新依赖包
- [ ] 审查性能指标
- [ ] 安全审计

## 三、故障排查

### 1. 服务无法启动

**问题**: 服务启动失败

**排查步骤**:
1. 检查端口是否被占用:
   ```bash
   # Windows
   netstat -ano | findstr :8000
   
   # Linux
   lsof -i :8000
   ```

2. 检查数据库连接:
   ```bash
   psql -U postgres -d intent_system -c "SELECT 1;"
   ```

3. 检查环境变量:
   ```bash
   # 确认 .env 文件存在且配置正确
   cat .env
   ```

4. 查看启动日志:
   ```bash
   python run.py 2>&1 | tee startup.log
   ```

### 2. API 响应慢

**问题**: API 响应时间过长

**排查步骤**:
1. 检查数据库查询:
   ```sql
   -- 查看慢查询
   SELECT * FROM pg_stat_statements 
   ORDER BY mean_exec_time DESC 
   LIMIT 10;
   ```

2. 检查 LLM API 调用:
   - 查看当前使用的 LLM 提供商与 Key（.env 中 `LLM_PROVIDER` 及对应 `*_API_KEY`）
   - 查看该提供商 API 响应时间与限流情况
   - 详见 [LLM 多提供商配置](07_LLM多提供商配置.md)

3. 检查向量检索:
   - 向量库大小是否过大
   - 检索的 top_k 是否过大

4. 检查系统资源:
   ```bash
   # CPU 和内存使用
   top
   # 或
   htop
   ```

### 3. 检索结果不准确

**问题**: 检索到的内容不相关

**排查步骤**:
1. 检查文档索引:
   ```bash
   # 重新索引文档
   curl -X POST http://localhost:8000/v1/resources/res_doc_xxx/reindex
   ```

2. 检查向量质量:
   - 确认嵌入模型正确
   - 检查文档分块是否合理

3. 调整权重配置:
   ```yaml
   # config/ranking.yaml
   weights:
     semantic: 0.6  # 提高语义权重
     keyword: 0.4
   ```

### 4. 数据库连接错误

**问题**: 数据库连接失败

**排查步骤**:
1. 检查 PostgreSQL 服务:
   ```bash
   # Windows
   services.msc  # 查看 PostgreSQL 服务状态
   
   # Linux
   systemctl status postgresql
   ```

2. 检查连接配置:
   ```bash
   # 测试连接
   psql -U postgres -d intent_system
   ```

3. 检查连接数:
   ```sql
   -- 查看当前连接数
   SELECT count(*) FROM pg_stat_activity;
   
   -- 查看最大连接数
   SHOW max_connections;
   ```

### 5. OpenAI API 错误

**问题**: LLM API 调用失败（OpenAI / DeepSeek / Claude / Qianwen）

**排查步骤**:
1. 检查当前使用的提供商及对应 API Key（.env 优先）:
   - OpenAI: `OPENAI_API_KEY`
   - DeepSeek: `DEEPSEEK_API_KEY`
   - Claude: `ANTHROPIC_API_KEY`
   - Qianwen: `DASHSCOPE_API_KEY`
   ```bash
   echo $OPENAI_API_KEY   # 或对应变量
   ```

2. 检查账户余额:
   - 登录当前使用的 LLM 平台查看余额

3. 检查限流:
   - 查看是否达到速率限制
   - 实现重试和退避机制

4. 检查网络:
   ```bash
   curl https://api.openai.com/v1/models \
     -H "Authorization: Bearer $OPENAI_API_KEY"
   ```

## 四、升级和维护

### 1. 依赖更新

**检查过时包**:
```bash
pip list --outdated
```

**更新依赖**:
```bash
# 更新单个包
pip install --upgrade package_name

# 更新所有包（谨慎）
pip install --upgrade -r requirements.txt
```

**测试更新**:
```bash
# 运行测试
pytest tests/

# 检查功能
curl http://localhost:8000/v1/health
```

### 2. 数据库迁移

**创建新迁移**:
```bash
# 自动生成迁移
alembic revision --autogenerate -m "描述"

# 手动创建迁移
alembic revision -m "描述"
```

**应用迁移**:
```bash
# 升级到最新
alembic upgrade head

# 升级到特定版本
alembic upgrade revision_id

# 降级
alembic downgrade -1
```

**迁移前备份**:
```bash
# 重要：迁移前必须备份
pg_dump -U postgres intent_system > backup_before_migration.sql
```

### 3. 代码更新

**更新流程**:
1. 备份当前版本
2. 拉取新代码
3. 更新依赖
4. 运行迁移
5. 测试功能
6. 重启服务

**回滚流程**:
1. 恢复代码
2. 恢复数据库（如需要）
3. 重启服务

## 五、安全维护

### 1. 定期更新

- [ ] 更新 Python 依赖包（修复安全漏洞）
- [ ] 更新 PostgreSQL（如有安全补丁）
- [ ] 更新系统包

### 2. 访问控制

- [ ] 定期审查 API 访问日志
- [ ] 检查异常访问模式
- [ ] 更新 API Key（如泄露）

### 3. 数据安全

- [ ] 定期备份数据库
- [ ] 加密敏感数据
- [ ] 审查数据访问权限

### 4. 日志审计

- [ ] 定期审查错误日志
- [ ] 检查异常操作
- [ ] 保留审计日志

## 六、性能优化

### 1. 数据库优化

**索引优化**:
```sql
-- 查看未使用的索引
SELECT * FROM pg_stat_user_indexes 
WHERE idx_scan = 0;

-- 创建缺失的索引
CREATE INDEX idx_resources_type_status ON resources(type, status);
```

**查询优化**:
```sql
-- 使用 EXPLAIN 分析查询
EXPLAIN ANALYZE SELECT * FROM resources WHERE type = 'DOC';
```

### 2. 缓存优化

**实现结果缓存**:
```python
# 使用 Redis 缓存常见查询结果
import redis
redis_client = redis.Redis()

def get_cached_answer(query):
    cache_key = f"answer:{hash(query)}"
    cached = redis_client.get(cache_key)
    if cached:
        return json.loads(cached)
    return None
```

### 3. 异步优化

**异步处理耗时操作**:
```python
# 使用异步任务处理文档索引
from celery import Celery

@celery_app.task
def async_reindex(resource_id):
    processor.reindex_resource(resource_id)
```

## 七、监控和告警

### 1. 健康检查

**实现健康检查端点**:
```python
@app.get("/v1/health/detailed")
async def detailed_health():
    checks = {
        'database': check_database(),
        'vector_store': check_vector_store(),
        'openai': check_openai()
    }
    return checks
```

### 2. 告警配置

**设置告警规则**:
- API 响应时间 > 5 秒
- 错误率 > 5%
- 数据库连接失败
- 磁盘空间 < 20%

**告警通知**:
- 邮件通知
- 短信通知
- 钉钉/企业微信通知

## 八、备份和恢复

### 1. 备份策略

**完整备份**（每日）:
- 数据库完整备份
- 向量库备份
- 配置文件备份

**增量备份**（每小时）:
- 数据库增量备份
- 日志文件备份

### 2. 恢复测试

**定期测试恢复**:
1. 在测试环境恢复备份
2. 验证数据完整性
3. 测试服务功能

## 九、维护检查清单

### 每日检查
- [ ] 服务运行正常
- [ ] 无严重错误日志
- [ ] API 响应时间正常
- [ ] 数据库连接正常

### 每周检查
- [ ] 数据库备份完成
- [ ] 清理过期数据
- [ ] 检查磁盘空间
- [ ] 审查错误日志

### 每月检查
- [ ] 数据库优化
- [ ] 更新依赖包
- [ ] 性能指标审查
- [ ] 安全审计

### 每季度检查
- [ ] 完整系统备份
- [ ] 恢复测试
- [ ] 容量规划
- [ ] 架构审查

## 十、提交说明规范（Commit）

代码仓库提交信息建议采用以下格式，便于追溯与发布说明：

**格式**:
```
<类型>: <简短描述（50 字内）>

- 具体改动 1
- 具体改动 2
（可选）涉及文档：doc/xx.md 已同步更新
```

**类型**：fix（修复）、feat（功能）、docs（文档）、refactor（重构）、perf（性能）、chore（杂项）

**示例**（基于 API 调用问题修复的一次提交）:
```
fix: 修复 Chat/工作流 API 若干问题并统一错误输出

- fix(answerer): 修正 _ensure_citations 中误用 any(bool) 导致 'bool' object is not iterable
- fix(chat): 编排器与 Chat API 异常时记录 traceback，对用户仅返回「处理时发生错误，请稍后重试」
- perf(检索): 单请求内按 resource_id 缓存 get_resource，减少 N+1 查询
- fix(workflow_engine): 先创建 Resource 再创建 Result，避免 results 表外键违反
- fix(workflow_api): 运行查询 404 时按 tenant_id 未查到则再按 run_id 查询
- feat(workflow_engine): 实现 RETRIEVE 步骤，调用 DOC 检索器返回 step_0.result
涉及文档：doc/03_使用说明.md、doc/05_故障排查.md 已同步
```
